# Exemplos de Uso do Dota Autoencoder

Este diretÃ³rio contÃ©m exemplos prÃ¡ticos de como usar o autoencoder para anÃ¡lise de partidas de Dota 2.

## Arquivos de Exemplo

### 1. `example_autoencoder_usage.py` - Exemplo Completo
Um exemplo abrangente que demonstra todas as funcionalidades do autoencoder:

- âœ… **ConfiguraÃ§Ã£o e carregamento de dados**
- âœ… **Treinamento completo com validaÃ§Ã£o**
- âœ… **VisualizaÃ§Ã£o do progresso de treinamento**
- âœ… **AnÃ¡lise do espaÃ§o latente com PCA**
- âœ… **Busca por similaridade entre partidas**
- âœ… **DetecÃ§Ã£o de anomalias**
- âœ… **AnÃ¡lise de qualidade de reconstruÃ§Ã£o**
- âœ… **Salvamento e carregamento de modelos**

**Como executar:**
```bash
python example_autoencoder_usage.py
```

**SaÃ­das geradas:**
- `training_history.png` - GrÃ¡fico do histÃ³rico de treinamento
- `latent_space_pca.png` - VisualizaÃ§Ã£o 2D do espaÃ§o latente
- `dota_autoencoder_model.pth` - Modelo treinado salvo

### 2. `quick_autoencoder_examples.py` - Exemplos RÃ¡pidos
Exemplos focados e diretos para casos de uso especÃ­ficos:

- ğŸš€ **Treinamento rÃ¡pido** - Como treinar rapidamente o modelo
- ğŸ” **AnÃ¡lise de similaridade** - Encontrar partidas similares
- ğŸš¨ **DetecÃ§Ã£o de anomalias** - Identificar partidas incomuns
- ğŸ¯ **ExtraÃ§Ã£o de features** - Obter representaÃ§Ãµes latentes
- ğŸ² **Clustering** - Agrupar partidas similares
- ğŸ’¾ **PersistÃªncia** - Salvar/carregar modelos

**Como executar:**
```bash
python quick_autoencoder_examples.py
```

## Casos de Uso Demonstrados

### 1. ğŸ§  Treinamento do Autoencoder
```python
from autoencoders import create_autoencoder_from_dataset

# Criar modelo automaticamente do dataset
model, processor = create_autoencoder_from_dataset(dataset_path)

# Treinar
trainer = DotaAutoencoderTrainer(model)
history = train_autoencoder(model, trainer, train_loader, val_loader)
```

### 2. ğŸ” AnÃ¡lise de Similaridade
```python
# Extrair representaÃ§Ãµes latentes
latent_representations = extract_latent_representations(model, data_loader)

# Encontrar partidas similares
similar_indices, similarities = find_similar_matches(
    latent_representations, 
    match_index=0, 
    top_k=5
)
```

### 3. ğŸš¨ DetecÃ§Ã£o de Anomalias
```python
# Detectar partidas anÃ´malas
anomaly_indices = detect_anomalies(
    latent_representations, 
    threshold_percentile=95
)
```

### 4. ğŸ“Š VisualizaÃ§Ã£o do EspaÃ§o Latente
```python
# Visualizar com PCA
analyze_latent_space(latent_representations, save_path="pca_plot.png")
```

### 5. ğŸ’¾ PersistÃªncia de Modelos
```python
# Salvar modelo completo
save_model(model, processor, "my_model.pth")

# Carregar modelo
loaded_model, loaded_processor = load_model("my_model.pth")
```

## ConfiguraÃ§Ã£o e Requisitos

### DependÃªncias
As dependÃªncias estÃ£o definidas no `pyproject.toml`:
- `torch` - PyTorch para deep learning
- `numpy` - ComputaÃ§Ã£o numÃ©rica
- `polars` - ManipulaÃ§Ã£o de dados
- `scikit-learn` - Preprocessing e mÃ©tricas
- `matplotlib` - VisualizaÃ§Ã£o
- `kagglehub` - Download do dataset

### InstalaÃ§Ã£o
```bash
# Se usando uv (recomendado)
uv sync

# Ou com pip
pip install -e .
```

## Estrutura dos Dados

O autoencoder processa dados de partidas de Dota 2 com:

### Entrada
- **HerÃ³is Radiant**: 5 herÃ³is do time Radiant
- **HerÃ³is Dire**: 5 herÃ³is do time Dire  
- **HerÃ³is Banidos**: AtÃ© 14 herÃ³is banidos na fase de draft
- **EstatÃ­sticas**: MÃ©tricas de performance dos jogadores
  - Kills, Deaths, Assists
  - Gold per minute, XP per minute

### SaÃ­da
- **RepresentaÃ§Ã£o Latente**: Vetor compacto representando a partida
- **ReconstruÃ§Ã£o**: ReconstruÃ§Ã£o das features originais

## ParÃ¢metros Importantes

### Modelo
```python
DotaMatchAutoencoder(
    max_heroes=150,           # NÃºmero mÃ¡ximo de herÃ³is
    embedding_dim=32,         # DimensÃ£o dos embeddings
    hidden_dims=[256,128,64], # Camadas ocultas
    latent_dim=32,           # DimensÃ£o do espaÃ§o latente
    dropout_rate=0.2         # Taxa de dropout
)
```

### Treinamento
```python
DotaAutoencoderTrainer(
    model=model,
    learning_rate=1e-3,      # Taxa de aprendizado
    weight_decay=1e-5        # RegularizaÃ§Ã£o L2
)
```

## Dicas de Uso

### ğŸ¯ Para Melhores Resultados
1. **Use mais dados**: Quanto mais partidas, melhor a qualidade das representaÃ§Ãµes
2. **Ajuste hiperparÃ¢metros**: Experimente diferentes dimensÃµes latentes e arquiteturas
3. **Normalize adequadamente**: O preprocessamento Ã© crucial para convergÃªncia
4. **Monitore overfitting**: Use validaÃ§Ã£o para evitar sobreajuste

### ğŸ”§ CustomizaÃ§Ã£o
- **Modifique `hidden_dims`** para arquiteturas diferentes
- **Ajuste `latent_dim`** baseado na complexidade desejada
- **Customize `dropout_rate`** para controlar regularizaÃ§Ã£o
- **Implemente novas mÃ©tricas** de loss se necessÃ¡rio

### ğŸ“Š AnÃ¡lise Downstream
As representaÃ§Ãµes latentes podem ser usadas para:
- **Clustering** de estilos de jogo
- **ClassificaÃ§Ã£o** de resultados
- **RecomendaÃ§Ã£o** de estratÃ©gias
- **DetecÃ§Ã£o** de padrÃµes meta

## SoluÃ§Ã£o de Problemas

### Erro de MemÃ³ria
```python
# Reduza o batch size
train_loader = DataLoader(dataset, batch_size=16)  # ao invÃ©s de 32

# Ou use menos dados
sample_data = dataset.sample(500)  # ao invÃ©s do dataset completo
```

### ConvergÃªncia Lenta
```python
# Aumente a learning rate
trainer = DotaAutoencoderTrainer(model, learning_rate=1e-2)

# Ou ajuste a arquitetura
model = DotaMatchAutoencoder(hidden_dims=[128, 64])  # Rede menor
```

### Resultados Ruins
1. **Verifique os dados**: Certifique-se que nÃ£o hÃ¡ valores faltantes
2. **Normalize features**: Especialmente as estatÃ­sticas numÃ©ricas
3. **Aumente Ã©pocas**: Modelo pode precisar de mais treinamento
4. **Experimente hiperparÃ¢metros**: Diferentes configuraÃ§Ãµes podem funcionar melhor

## Contribuindo

Para adicionar novos exemplos:
1. Crie um novo arquivo `.py` com exemplos especÃ­ficos
2. Documente claramente o caso de uso
3. Inclua comentÃ¡rios explicativos
4. Teste com dados reais
5. Atualize este README

---

**Nota**: Os exemplos usam uma amostra pequena dos dados para execuÃ§Ã£o rÃ¡pida. Para resultados em produÃ§Ã£o, use o dataset completo e treine por mais Ã©pocas.
